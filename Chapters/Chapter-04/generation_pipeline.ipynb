{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://mng.bz/8wdg\" target=\"_blank\">\n",
    "    <img src=\"../../Assets/Images/NewMEAPHeader.png\" alt=\"New MEAP\" style=\"width: 100%;\" />\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 04 - Generation Pipeline: Generating Contextual LLM Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to chapter 4 of A Simple Introduction to Retrieval Augmented Generation.\n",
    "\n",
    "In this chapter, we introduce the concepts behind the real-time generation pipeline that uses the knowledge base created by the indexing pipeline. This will complete the development of a simple RAG system.\n",
    "\n",
    "The generation pipeline consists of three steps -\n",
    "\n",
    "1. Retrieval\n",
    "2. Augmentation\n",
    "3. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../Assets/Images/4.1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the necessary libraries for running this notebook along with their versions can be found in __requirements.txt__ file in the root directory of this repository\n",
    "\n",
    "You should go to the root directory and run the following command to install the libraries\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "This is the recommended method of installing the dependencies\n",
    "\n",
    "___\n",
    "Alternatively, you can run the command from this notebook too. The relative path may vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Vector Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 3, we were working on indexing the Wikipedia page for the 2023 cricket world cup. If you recall we had used embeddings from OpenAI to encode the text and used FAISS as the vector index to store the embeddings. We also stored the FAISS index in a local directory. Let’s reuse this index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You will need an __OpenAI API Key__ which can be obtained from [OpenAI](https://platform.openai.com/api-keys) to reuse the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the __OpenAI client__, we need to pass the api key. There are many ways of doing it. \n",
    "\n",
    "####  [Option 1] Creating a .env file for storing the API key and using it # Recommended\n",
    "\n",
    "Install the __dotenv__ library\n",
    "\n",
    "_The dotenv library is a popular tool used in various programming languages, including Python and Node.js, to manage environment variables in development and deployment environments. It allows developers to load environment variables from a .env file into their application's environment._\n",
    "\n",
    "- Create a file named .env in the root directory of their project.\n",
    "- Inside the .env file, then define environment variables in the format VARIABLE_NAME=value. \n",
    "\n",
    "e.g.\n",
    "\n",
    "OPENAI_API_KEY=YOUR API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: .env file found with some environment variables\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Success: .env file found with some environment variables\")\n",
    "else:\n",
    "    print(\"Caution: No environment variables found. Please create .env file in the root directory or add environment variables in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Option 2] Alternatively, you can set the API key in code. \n",
    "However, this is not recommended since it can leave your key exposed for potential misuse. Uncomment the cell below to use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-******\" #Imp : Replace with an OpenAI API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test if the key is valid or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set and is valid\n"
     ]
    }
   ],
   "source": [
    "api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "if api_key:\n",
    "    try:\n",
    "        client.models.list()\n",
    "        print(\"OPENAI_API_KEY is set and is valid\")\n",
    "    except openai.APIError as e:\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "        pass\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"Failed to connect to OpenAI API: {e}\")\n",
    "        pass\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    print(\"Please set you OpenAI API key as an environment variable OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenAIEmbeddings from the library\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Instantiate the embeddings object\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Import FAISS from langchain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Load the FAISS vector store with safe deserialization\n",
    "vector_store = FAISS.load_local(folder_path=\"../../Assets/Data/\",index_name=\"CWC_index\", embeddings=embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now retrieve a relevant passage from the knowledge base that is pertinent to our query - __\"Who won the World Cup final?\"__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../Assets/Images/4.2.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrieved Chunk 1: The tournament was contested by ten national teams, maintaining the same format\n",
      "used in  2019 . After six weeks of round-robin matches,  India ,  South Africa ,  Australia , and\n",
      "New Zealand  finished as the top four and qualified for the knockout stage. In the knockout stage,\n",
      "India and Australia beat New Zealand and South Africa, respectively, to advance to the final, played\n",
      "on 19 November at the  Narendra Modi Stadium  in  Ahmedabad . Australia won the final by six\n",
      "wickets, winning their sixth Cricket World Cup title.\n",
      "\n",
      "\n",
      "\n",
      " Retrieved Chunk 2: The host  India  was the first team to qualify for the semi-finals after their\n",
      "302-run win against  Sri Lanka , their seventh successive win in the World Cup. [ 42 ]  India\n",
      "secured the top place amongst the semi-finalists after they beat  South Africa  by 243 runs on 5\n",
      "November at  Eden Gardens  in  Kolkata . [ 43 ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the query\n",
    "query = \"Who won the world cup?\"\n",
    "\n",
    "# Perform similarity search\n",
    "retrieved_docs = vector_store.similarity_search(query, k=2)  # Get top 2 relevant chunks\n",
    "\n",
    "# Display results\n",
    "\n",
    "import textwrap\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(textwrap.fill(f\"\\nRetrieved Chunk {i+1}:\\n{doc.page_content}\",width=100))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most basic implementation of a retriever in the generation pipeline of a RAG-enabled system. This method of retrieval is enabled by embeddings. We used the text-embedding-3-small from OpenAI. FAISS calculated the similarity score based on these embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information fetched by the retriever should also be sent to the LLM in form of a natural language prompt. This process of combining the user query and the retrieved information is called augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../Assets/Images/4.3.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now execute augmentation with a simple contextual prompt with controlled generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Given the context below answer the question.  Question: Who won the world cup?   Context : The tournament was contested by ten national teams,\n",
      "maintaining the same format used in  2019 . After six weeks of round-robin matches,  India ,  South Africa ,  Australia , and  New Zealand  finished\n",
      "as the top four and qualified for the knockout stage. In the knockout stage, India and Australia beat New Zealand and South Africa, respectively, to\n",
      "advance to the final, played on 19 November at the  Narendra Modi Stadium  in  Ahmedabad . Australia won the final by six wickets, winning their sixth\n",
      "Cricket World Cup title.The host  India  was the first team to qualify for the semi-finals after their 302-run win against  Sri Lanka , their seventh\n",
      "successive win in the World Cup. [ 42 ]  India secured the top place amongst the semi-finalists after they beat  South Africa  by 243 runs on 5\n",
      "November at  Eden Gardens  in  Kolkata . [ 43 ]  Remember to answer only based on the context provided and not from any other source.   If the\n",
      "question cannot be answered based on the provided context, say I don’t know.\n"
     ]
    }
   ],
   "source": [
    "# taking first two retrieved documents\n",
    "retrieved_context=retrieved_docs[0].page_content + retrieved_docs[1].page_content\n",
    "\n",
    "# Creating the prompt\n",
    "augmented_prompt=f\"\"\"\n",
    "\n",
    "Given the context below answer the question.\n",
    "\n",
    "Question: {query} \n",
    "\n",
    "Context : {retrieved_context}\n",
    "\n",
    "Remember to answer only based on the context provided and not from any other source. \n",
    "\n",
    "If the question cannot be answered based on the provided context, say I don’t know.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(textwrap.fill(augmented_prompt,width=150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation is the final step of this pipeline. While LLMs may be used in any of the previous steps in the pipeline, the generation step is completely reliant on the LLM. The most popular LLMs are the ones being developed by OpenAI, Anthropic, Meta, Google, Microsoft and Mistral amongst other developers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built a simple retriever using FAISS and OpenAI embeddings and, we created a simple augmented prompt. Now we will use OpenAI’s latest model, GPT-4o-mini, to generate the response. To do this we will import the __ChatOpenAI__ library from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia won the world cup.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Set up LLM and embeddings\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "messages=[(\"human\",augmented_prompt)]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "\n",
    "\n",
    "\n",
    "# Extract the answer from the response object\n",
    "answer=ai_msg.content\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. RAG function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build a function that will take three inputs - \n",
    "1. User Query\n",
    "2. Location of the Vector Index (Knowledge base)\n",
    "3. Index Name\n",
    "\n",
    "And generate an answer along with the retrieved documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Replace non-breaking space with regular space\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    \n",
    "    # Remove any HTML tags (if any)\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Removes HTML tags\n",
    "    \n",
    "    # Remove references in brackets (e.g., [7], [39])\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Removes references inside square brackets\n",
    "    \n",
    "    # Remove extra spaces and newlines\n",
    "    text = ' '.join(text.split())  # This will remove extra spaces and newline characters\n",
    "    \n",
    "    return text\n",
    "\n",
    "def rag_function(query, db_path, index_name):\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    db=FAISS.load_local(folder_path=db_path, index_name=index_name, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "    retrieved_docs = db.similarity_search(query, k=2)\n",
    "\n",
    "    retrieved_context=[clean_text(retrieved_docs[0].page_content + retrieved_docs[1].page_content)]\n",
    "\n",
    "\n",
    "    augmented_prompt=f\"\"\"\n",
    "\n",
    "    Given the context below answer the question.\n",
    "\n",
    "    Question: {query} \n",
    "\n",
    "    Context : {retrieved_context}\n",
    "\n",
    "    Remember to answer only based on the context provided and not from any other source. \n",
    "\n",
    "    If the question cannot be answered based on the provided context, say I don’t know.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    "    )\n",
    "\n",
    "    messages=[(\"human\",augmented_prompt)]\n",
    "\n",
    "    ai_msg = llm.invoke(messages)\n",
    "\n",
    "    response=ai_msg.content\n",
    "\n",
    "    return retrieved_context, response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try sending our question to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The tournament was contested by ten national teams, maintaining the same format used in 2019 . After six weeks of round-robin matches, India , South Africa , Australia , and New Zealand finished as the top four and qualified for the knockout stage. In the knockout stage, India and Australia beat New Zealand and South Africa, respectively, to advance to the final, played on 19 November at the Narendra Modi Stadium in Ahmedabad . Australia won the final by six wickets, winning their sixth Cricket World Cup title.The host India was the first team to qualify for the semi-finals after their 302-run win against Sri Lanka , their seventh successive win in the World Cup. India secured the top place amongst the semi-finalists after they beat South Africa by 243 runs on 5 November at Eden Gardens in Kolkata .'],\n",
       " 'Australia won the world cup.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_function(query=\"Who won the world cup?\", db_path=\"../../Assets/Data\", index_name=\"CWC_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Virat Kohli was named the player of the tournament and also scored the most runs, while Mohammed Shami was the leading wicket-taker. A total of 1,250,307 spectators attended the matches, the highest number in any Cricket World Cup to date. The tournament final set viewership records in India, drawing 518 million viewers, with a peak of 57 million streaming viewers.The ICC announced its team of the tournament on 21 November 2023, with Virat Kohli being named as player of the tournament , and Rohit Sharma as captain of the team.'],\n",
       " 'Virat Kohli was named the player of the tournament and scored the most runs.')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_function(\"What was Virat Kohli's achievement in the Cup?\",db_path=\"../../Assets/Data\", index_name=\"CWC_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask a list of questions and see what the responses are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_queries=['What was the outcome of the match between Australia and the Netherlands on 25 October 2023?',\n",
    " 'What ongoing cricket competition is currently taking place that involves multiple international teams?',\n",
    " 'What was the deadline for teams to finalize their 15-player squads for the 2023 Cricket World Cup?',\n",
    " \"What were the key highlights of the 2023 ICC Men's Cricket World Cup?\",\n",
    " 'What were the key outcomes of the 2023 Cricket World Cup, including the final match results and notable player statistics?',\n",
    " 'What years had Cricket World Cup finals and their host nations?',\n",
    " \"Which org has managed the Cricket World Cup since '75?\",\n",
    " \"What was India's winning margin vs. S. Africa on Nov 5, 2023?\",\n",
    " 'What teams qualified for the semi-finals in the 2023 Cricket World Cup?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:What was the outcome of the match between Australia and the Netherlands on 25 October 2023?\n",
      "Response: I don’t know.\n",
      "\n",
      "Query:What ongoing cricket competition is currently taking place that involves multiple international teams?\n",
      "Response: I don’t know.\n",
      "\n",
      "Query:What was the deadline for teams to finalize their 15-player squads for the 2023 Cricket World Cup?\n",
      "Response: The deadline for teams to finalize their 15-player squads for the 2023 Cricket World Cup was 28 September.\n",
      "\n",
      "Query:What were the key highlights of the 2023 ICC Men's Cricket World Cup?\n",
      "Response: The key highlights of the 2023 ICC Men's Cricket World Cup include:\n",
      "\n",
      "- Dates: 5 October – 19 November 2023\n",
      "- Host: India (first time as the sole host)\n",
      "- Format: One Day International (ODI) with a round-robin and knockout tournament structure\n",
      "- Participants: 10 teams\n",
      "- Matches: 48 played\n",
      "- Attendance: 1,250,307 (average of 26,048 per match)\n",
      "- Champions: Australia (6th title)\n",
      "- Runners-up: India\n",
      "- Player of the Series: Virat Kohli\n",
      "- Most Runs: Virat Kohli (765 runs)\n",
      "- Most Wickets: Mohammed Shami (24 wickets)\n",
      "\n",
      "Query:What were the key outcomes of the 2023 Cricket World Cup, including the final match results and notable player statistics?\n",
      "Response: I don’t know.\n",
      "\n",
      "Query:What years had Cricket World Cup finals and their host nations?\n",
      "Response: The years that had Cricket World Cup finals and their host nations are as follows:\n",
      "\n",
      "- 1975: England\n",
      "- 1979: England\n",
      "- 1983: England / Wales\n",
      "- 1987: Australia / New Zealand\n",
      "- 1992: Pakistan / India / Sri Lanka\n",
      "- 1996: England / Scotland / Wales / Ireland / Netherlands\n",
      "- 1999: South Africa / Zimbabwe / Kenya\n",
      "- 2003: West Indies\n",
      "- 2007: India / Sri Lanka / Bangladesh\n",
      "- 2011: Australia / New Zealand\n",
      "- 2015: England / Wales\n",
      "- 2019: India\n",
      "- 2023: South Africa / Zimbabwe / Namibia\n",
      "\n",
      "Query:Which org has managed the Cricket World Cup since '75?\n",
      "Response: The organization that has managed the Cricket World Cup since 1975 is the International Cricket Council (ICC).\n",
      "\n",
      "Query:What was India's winning margin vs. S. Africa on Nov 5, 2023?\n",
      "Response: I don’t know.\n",
      "\n",
      "Query:What teams qualified for the semi-finals in the 2023 Cricket World Cup?\n",
      "Response: I don’t know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in list_of_queries:\n",
    "    print(f\"Query:{query}\")\n",
    "    print(f\"Response: {rag_function(query,db_path=\"../../Assets/Data\", index_name=\"CWC_index\")[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the questions above, the response may be \"I don't know\". That is when the LLM can't find an answer in the retrieved context. In our augmentation step, we had asked the LLM to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the RAG system that we have created generating the responses on the expected lines? Is the LLM still hallucinating? Before trying to improve the performance of the system we need to be able to measure and benchmark it. That is what we will do in chapter 5. We will look at the evaluation metrics and the popular benchmarks for RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../Assets/Images/profile_s.png\" width=100> \n",
    "\n",
    "Hi! I'm Abhinav! I am an entrepreneur and Vice President of Artificial Intelligence at Yarnit. I have spent over 15 years consulting and leadership roles in data science, machine learning and AI. My current focus is in the applied Generative AI domain focussing on solving enterprise needs through contextual intelligence. I'm passionate about AI advancements constantly exploring emerging technologies to push the boundaries and create positive impacts in the world. Let’s build the future, together!\n",
    "\n",
    "[If you haven't already, please subscribe to the MEAP of A Simple Guide to Retrieval Augmented Generation here](https://mng.bz/8wdg)\n",
    "\n",
    "<a href=\"https://mng.bz/8wdg\" target=\"_blank\">\n",
    "    <img src=\"../../Assets/Images/NewMEAPFooter.png\" alt=\"New MEAP\" style=\"width: 100%;\" />\n",
    "</a>\n",
    "\n",
    "#### If you'd like to chat, I'd be very happy to connect\n",
    "\n",
    "[![GitHub followers](https://img.shields.io/badge/Github-000000?style=for-the-badge&logo=github&logoColor=black&color=orange)](https://github.com/abhinav-kimothi)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-000000?style=for-the-badge&logo=linkedin&logoColor=orange&color=black)](https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=abhinav-kimothi)\n",
    "[![Medium](https://img.shields.io/badge/Medium-000000?style=for-the-badge&logo=medium&logoColor=black&color=orange)](https://medium.com/@abhinavkimothi)\n",
    "[![Insta](https://img.shields.io/badge/Instagram-000000?style=for-the-badge&logo=instagram&logoColor=orange&color=black)](https://www.instagram.com/akaiworks/)\n",
    "[![Mail](https://img.shields.io/badge/email-000000?style=for-the-badge&logo=gmail&logoColor=black&color=orange)](mailto:abhinav.kimothi.ds@gmail.com)\n",
    "[![X](https://img.shields.io/badge/Follow-000000?style=for-the-badge&logo=X&logoColor=orange&color=black)](https://twitter.com/abhinav_kimothi)\n",
    "[![Linktree](https://img.shields.io/badge/Linktree-000000?style=for-the-badge&logo=linktree&logoColor=black&color=orange)](https://linktr.ee/abhinavkimothi)\n",
    "[![Gumroad](https://img.shields.io/badge/Gumroad-000000?style=for-the-badge&logo=gumroad&logoColor=orange&color=black)](https://abhinavkimothi.gumroad.com/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sgragch4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
